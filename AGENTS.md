# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Обзор проекта

Автоматизированная система для парсинга объявлений с Авито по артикулам с многоуровневой валидацией и распределенной обработкой через независимые воркеры.

**Основные принципы:**
- Никогда не врать - если что-то неизвестно, так и говорить
- Добавлять небольшие, но понятные комментарии в код
- При необходимости использовать web search
- Не создавать версии проекта и не упоминать версионирование
- Всегда актуализировать документацию в [docs/doc.md](docs/doc.md)

**Основные возможности:**
- Массовый парсинг объявлений по списку артикулов
- Двухуровневая валидация (механическая + ИИ)
- Автоматическое определение неоригинальных товаров
- Ценовой анализ и фильтрация подозрительных предложений
- Сохранение детальной информации о каждом объявлении
- Автоматическое решение капчи
- Работа через прокси с автоматической ротацией

## Технологический стек

- **PostgreSQL** - основная БД для очередей и хранения данных
- **avito-library** - специализированная библиотека для парсинга на базе Playwright (КРИТИЧЕСКАЯ зависимость)
- **Docker + Docker Compose** - контейнеризация и оркестрация
- **Python 3.11+** - минимальная требуемая версия
- **asyncpg** - асинхронный драйвер PostgreSQL
- **Gemini 2.5-flash** - ИИ-валидация через OpenAI-совместимый API

Все зависимости должны быть максимальных версий.

## Структура проекта

**ВАЖНО:** Проект состоит из двух основных папок: `container` и `scripts`

```
/root/avito_zamer_complex-1/
├── container/          # Реализация Docker-воркера
│   ├── worker/        # Ядро логики воркера
│   │   ├── config.py          # Конфигурация из переменных окружения
│   │   ├── database.py        # 12 атомарных операций с БД
│   │   ├── browser.py         # Управление Playwright браузером
│   │   ├── main.py            # Основной цикл воркера
│   │   ├── errors.py          # Кастомные исключения
│   │   ├── stopwords.py       # Списки стоп-слов
│   │   └── validation/        # Двухуровневая валидация
│   │       ├── mechanical.py  # Стоп-слова + ценовой фильтр
│   │       └── ai.py          # ИИ-валидация через Gemini
│   ├── supervisor.py           # Менеджер multiprocessing
│   ├── healthcheck.sh          # Мониторинг здоровья
│   ├── check_dependencies.py  # Проверка зависимостей
│   └── Dockerfile
├── scripts/           # Локальные скрипты управления
│   ├── add_tasks.py          # Загрузка артикулов из data/urls.txt
│   ├── manage_proxies.py     # Загрузка прокси из data/proxies.txt
│   ├── monitor.py            # Мониторинг системы
│   ├── clear_database.py     # Интерактивная очистка таблиц
│   ├── check_queue.py        # Проверка статуса очереди
│   ├── free_proxies.py       # Освобождение заблокированных прокси
│   └── db_utils.py           # Общие утилиты БД
└── docs/doc.md       # Полная спецификация алгоритмов
```

## Основные команды

### Операции с Docker

**КРИТИЧЕСКИ ВАЖНО:** Все команды docker compose ДОЛЖНЫ выполняться ТОЛЬКО из корня проекта (`/root/avito_zamer_complex-1/`)

```bash
# Сборка контейнера
docker compose build

# Запуск контейнера
docker compose up -d

# Просмотр логов
docker compose logs -f

# Остановка контейнера
docker compose down
```

### Локальные скрипты управления

Все скрипты работают в интерактивном режиме с батчевыми операциями (1000 записей) и атомарными транзакциями.

```bash
# Загрузка артикулов (из scripts/data/urls.txt)
cd /root/avito_zamer_complex-1
python scripts/add_tasks.py

# Управление прокси (из scripts/data/proxies.txt)
python scripts/manage_proxies.py

# Мониторинг состояния системы
python scripts/monitor.py

# Очистка таблиц БД
python scripts/clear_database.py

# Проверка статуса очереди
python scripts/check_queue.py

# Освобождение заблокированных прокси
python scripts/free_proxies.py
```

### Конфигурация окружения

Настройка через файл `.env` в корне проекта:

```bash
# Подключение к БД
DB_HOST=81.30.105.134
DB_PORT=5417
DB_NAME=system_avito_zamer
DB_USER=admin
DB_PASSWORD=<пароль>

# Настройки воркеров
NUM_WORKERS=15              # Количество процессов воркеров
HEARTBEAT_INTERVAL=120      # Интервал обновления heartbeat (секунды)
STUCK_TASK_TIMEOUT=3600     # Таймаут для определения зависшей задачи (секунды)
MAX_RETRY_ATTEMPTS=3        # Максимум попыток на задачу

# ИИ-валидация
GEMINI_API_KEY=<ваш_ключ>   # Требуется для ИИ-валидации
```

## Архитектура

### Компоненты системы

- **Локальные скрипты** - управление задачами, прокси, мониторинг
- **Контейнеризированные воркеры** - выполнение парсинга на серверах
- **PostgreSQL БД** - централизованное хранилище данных и очередь задач
- **Avito Library** - основной инструмент взаимодействия с сайтом

### Принцип работы

1. Локальные скрипты загружают артикулы и прокси в БД
2. Воркеры асинхронно берут задачи из очереди
3. Каждый воркер независимо обрабатывает свои задачи
4. Результаты сохраняются в БД с полной историей валидации

### Архитектура multiprocessing

**Один контейнер + множество воркеров:**
- ОДИН Docker контейнер запускает supervisor.py
- Supervisor управляет N процессами воркеров через multiprocessing (по умолчанию: 15)
- Каждый процесс - независимый асинхронный воркер (asyncio)
- Автоматический перезапуск упавших воркеров
- Каждый воркер получает свой виртуальный дисплей (Xvfb) для браузеров

**Важно:** НЕ 15 контейнеров - ОДИН контейнер с 15 процессами внутри.

### Схема базы данных

Пять основных таблиц:
- `tasks` - артикулы для парсинга (статусы: 'новая', 'в работе', 'завершена', 'ошибка')
- `proxies` - пул прокси (статусы: 'свободен', 'используется', 'заблокирован')
- `parsed_cards` - данные спаршенных объявлений
- `validation_results` - результаты валидации (механическая + ИИ)
- `processed_articles` - история обработки

**Важно:** Все статусы в БД - на русском языке согласно схеме.

### Процесс работы воркера

1. **Инициализация** - Проверка зависимостей (avito-library ОБЯЗАТЕЛЬНА, режима заглушки нет)
2. **Восстановление зависших задач** - Возврат задач с heartbeat > 1 часа в очередь
3. **Атомарное взятие задачи** - `FOR UPDATE SKIP LOCKED` предотвращает коллизии
4. **Атомарное взятие прокси** - Случайный выбор из доступных
5. **Запуск браузера** - Playwright с прокси, переиспользуется между задачами
6. **Парсинг каталога** - Парсинг ВСЕХ страниц (без ограничений) через паттерн оркестратор-координатор
7. **Двухуровневая валидация**:
   - Механическая: стоп-слова + ценовой фильтр (порог 50%)
   - ИИ: анализ через Gemini 2.5-flash (порог 70%)
8. **Детальный парсинг карточек** - Парсинг отдельных объявлений, прошедших валидацию
9. **Завершение задачи** - Обновление статуса, сохранение браузера/прокси для следующей задачи
10. **Цикл heartbeat** - Обновление каждые 120с в фоне для подтверждения работы воркера

### Критические технические требования

**ОБЯЗАТЕЛЬНО:**
- Использовать Avito Library для ВСЕХ операций с сайтом
- Максимально долгое переиспользование браузерной страницы
- Независимая работа воркеров без взаимной блокировки
- Атомарное взятие задач и прокси из БД
- Heartbeat механизм для отслеживания живых воркеров
- Вызов детектора после КАЖДОГО перехода на страницу
- Использовать `headless=false` для браузера
- Проект состоит из двух папок: container и scripts
- Русские значения статусов в операциях с БД

**Валидация:**
- Механическая проверка на стоп-слова (б/у, аналог, не оригинал)
- Ценовой фильтр: отсечение объявлений дешевле 50% от топ-20%
- ИИ-валидация всех прошедших механическую проверку
- Сохранение результатов валидации в JSON для аудита

**Ограничения:**
- НЕ поддерживается частичный парсинг каталога
- НЕ поддерживается параллельный парсинг одного артикула
- НЕ восстанавливаются заблокированные прокси
- НЕ используется батчевая обработка для ИИ-валидации

### Управление ресурсами

**Переиспользование браузера:** Экземпляр Page переиспользуется между задачами до:
- Блокировки прокси (403/407)
- Нерешаемой капчи
- Остановки воркера

**Пулы соединений:**
- На воркер: 2-5 соединений (POOL_MIN_SIZE/POOL_MAX_SIZE)
- Всего: NUM_WORKERS × POOL_MAX_SIZE < 100 (лимит PostgreSQL)
- По умолчанию: 15 воркеров × 5 = 75 соединений

**Память:**
- shm_size: 6GB для 15 браузеров Chromium
- Каждый браузер: ~300-400MB на пиках

### Обработка ошибок

**Фатальные ошибки (прокси заблокирован, нерешаемая капча):**
1. Блокировка прокси в БД
2. Закрытие браузера
3. Возврат задачи в очередь (инкремент счетчика retry)
4. Получение нового прокси и задачи

**Исчерпаны попытки (3 retry):**
- Пометить задачу как 'ошибка'
- Больше не пытаться обработать этот артикул

**Нет доступных ресурсов:**
- Нет прокси: ждать 60с, не брать задачи
- Нет задач: ждать 30с, повторить

**Graceful shutdown (SIGTERM):**
1. Установить running = False
2. Отменить heartbeat
3. Вернуть задачу в очередь
4. Освободить прокси
5. Закрыть браузер
6. Закрыть пул БД

### Виртуальные дисплеи (Xvfb)

Каждый воркер получает выделенный виртуальный дисплей:
- Воркер 1 → DISPLAY=:99
- Воркер 2 → DISPLAY=:100
- Воркер N → DISPLAY=:98+N

Процессы Xvfb управляются в entrypoint.sh с корректным cleanup при EXIT/SIGTERM/SIGINT.

## Принципы разработки

**KISS (Keep It Simple, Stupid):**
- Простая архитектура без лишних абстракций
- Прямое подключение к БД без API-слоев
- Минимум внешних зависимостей
- Один воркер = одна задача = один прокси
- Случайный выбор прокси вместо сложных алгоритмов

**Отказоустойчивость:**
- Автоматический перезапуск упавших воркеров
- Возврат зависших задач в очередь через час
- Независимая работа воркеров
- Сохранение промежуточных результатов

## Частые проблемы

1. **Отсутствует avito-library:** Воркер не запустится (режима заглушки нет) - проверить зависимости
2. **Слишком много соединений БД:** Убедиться что NUM_WORKERS × POOL_MAX_SIZE < 100
3. **Падения браузера:** Проверить что shm_size достаточен (6GB для 15 воркеров)
4. **Зависшие задачи:** Проверить работу heartbeat механизма
5. **Неправильный docker-compose.yml:** Использовать корневой docker-compose.yml, НЕ container/docker-compose.yml (удален)

## Полная документация

Полная спецификация алгоритмов и детали реализации: [docs/doc.md](docs/doc.md)
